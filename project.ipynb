{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import data_loader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper.py\n",
    "\n",
    "# Count the number of parameters\n",
    "def count_param(model):\n",
    "    return sum([torch.numel(param) for param in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_data(N=1000, batch_size=50, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, data_loader):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for data_input, data_target, data_classes in data_loader:\n",
    "        data_target = torch.nn.functional.one_hot(data_target)\n",
    "        output = model(data_input)\n",
    "        nb_error = torch.sum(torch.argmax(output, dim=1, keepdim=True) != torch.argmax(data_target, dim=1, keepdim=True))\n",
    "        nb_data_errors += nb_error\n",
    "        \n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors_siamese(model, data_loader):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "    for data_input, data_target, data_classes in data_loader:\n",
    "        data_1, data_2 = data_input.unbind(1)               \n",
    "        output = model(data_1.unsqueeze(1), data_2.unsqueeze(1))\n",
    "        data_target = torch.nn.functional.one_hot(data_target)\n",
    "        nb_error = torch.sum(torch.argmax(output, dim=1, keepdim=True) != torch.argmax(data_target, dim=1, keepdim=True))\n",
    "        nb_data_errors += nb_error\n",
    "        \n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors_auxsiamese(model, data_loader):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "    for data_input, data_target, data_classes in data_loader:\n",
    "        data_1, data_2 = data_input.unbind(1)               \n",
    "        output, aux1, aux2 = model(data_1.unsqueeze(1), data_2.unsqueeze(1))\n",
    "        data_target = torch.nn.functional.one_hot(data_target)\n",
    "        nb_error = torch.sum(torch.argmax(output, dim=1, keepdim=True) != torch.argmax(data_target, dim=1, keepdim=True))\n",
    "        nb_data_errors += nb_error\n",
    "        \n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3)    # size [nb, 32, 12, 12]\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)   # size [nb, 64, 4, 4]\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "        self.fc3 = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2)) # size [nb, 32, 6, 6]      \n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2)) # size [nb, 64, 2, 2]\n",
    "        x = x.view(-1, 256) # size [nb, 256]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseBaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseBaseNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)    # size [nb, 32, 10, 10]\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)   # size [nb, 64, 4, 4]\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "        \n",
    "    def convs(self, x):        \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2)) # size [nb, 32, 5, 5]      \n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2)) # size [nb, 64, 2, 2]\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.convs(x1)\n",
    "        x1 = x1.view(-1, 256)\n",
    "        x1 = F.relu((self.fc1(x1)))\n",
    "        x1 = F.relu(self.fc2(x1))\n",
    "        \n",
    "        x2 = self.convs(x2)\n",
    "        x2 = x2.view(-1, 256)\n",
    "        x2 = F.relu(self.fc1(x2))\n",
    "        x2 = F.relu(self.fc2(x2))\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        #x = torch.abs(x1 - x2)\n",
    "        #x = F.relu(self.fc1(x.flatten(start_dim=1)))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxsiameseBaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AuxsiameseBaseNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)    # size [nb, 32, 10, 10]\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)   # size [nb, 64, 4, 4]\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "        \n",
    "    def convs(self, x):        \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2)) # size [nb, 32, 5, 5]      \n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2)) # size [nb, 64, 2, 2]\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.convs(x1)\n",
    "        x1 = x1.view(-1, 256)\n",
    "        x1 = F.relu((self.fc1(x1)))\n",
    "        x1 = F.relu(self.fc2(x1))\n",
    "        \n",
    "        x2 = self.convs(x2)\n",
    "        x2 = x2.view(-1, 256)\n",
    "        x2 = F.relu(self.fc1(x2))\n",
    "        x2 = F.relu(self.fc2(x2))\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        aux1 = F.softmax(x1)\n",
    "        aux2 = F.softmax(x2)\n",
    "        #x = torch.abs(x1 - x2)\n",
    "        #x = F.relu(self.fc1(x.flatten(start_dim=1)))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        \n",
    "        return x, aux1, aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxBaseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AuxBaseNet, self).__init__()\n",
    "        self.conv11 = nn.Conv2d(1, 32, kernel_size=3)    # size [nb, 32, 10, 10]\n",
    "        self.conv21 = nn.Conv2d(32, 64, kernel_size=3)   # size [nb, 64, 4, 4]\n",
    "        self.fc11 = nn.Linear(256, 200)\n",
    "        self.fc21 = nn.Linear(200, 10)\n",
    "        self.conv12 = nn.Conv2d(1, 32, kernel_size=5)    # size [nb, 32, 10, 10]\n",
    "        self.conv22 = nn.Conv2d(32, 64, kernel_size=2)   # size [nb, 64, 4, 4]\n",
    "        self.fc12 = nn.Linear(256, 200)\n",
    "        self.fc22 = nn.Linear(200, 10)\n",
    "        self.fc3 = nn.Linear(20, 2)\n",
    "        \n",
    "    def convs(self, x):        \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2)) # size [nb, 32, 5, 5]      \n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2)) # size [nb, 64, 2, 2]\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = F.relu(F.max_pool2d(self.conv11(x1), kernel_size=2)) # size [nb, 32, 5, 5]  \n",
    "        x1 = F.relu(F.max_pool2d(self.conv21(x1), kernel_size=2)) # size [nb, 64, 2, 2]\n",
    "        x1 = x1.view(-1, 256)\n",
    "        x1 = F.relu((self.fc11(x1)))\n",
    "        x1 = F.relu(self.fc21(x1))\n",
    "        \n",
    "        x2 = F.relu(F.max_pool2d(self.conv12(x2), kernel_size=2)) # size [nb, 32, 5, 5]  \n",
    "        x2 = F.relu(F.max_pool2d(self.conv22(x2), kernel_size=2)) # size [nb, 64, 2, 2]\n",
    "        x2 = x2.view(-1, 256)\n",
    "        x2 = F.relu((self.fc12(x2)))\n",
    "        x2 = F.relu(self.fc22(x2))\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        aux1 = F.softmax(x1)\n",
    "        aux2 = F.softmax(x2)\n",
    "        #x = torch.abs(x1 - x2)\n",
    "        #x = F.relu(self.fc1(x.flatten(start_dim=1)))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        \n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        \n",
    "        return x, aux1, aux2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNetBlock with skip-connection and batch normalization\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, nb_channels, kernel_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(nb_channels, nb_channels,\n",
    "                               kernel_size = kernel_size,\n",
    "                               padding = (kernel_size - 1) // 2)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(nb_channels, nb_channels,\n",
    "                               kernel_size = kernel_size,\n",
    "                               padding = (kernel_size - 1) // 2)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(nb_channels)\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.bn1(y)\n",
    "        #y = self.dropout(y)\n",
    "        y = F.relu(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.bn2(y)\n",
    "        #y = self.dropout(y)\n",
    "        y = y + x\n",
    "        y = F.relu(y)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, nb_residual_blocks, input_channels, nb_channels,\n",
    "                 kernel_size = 3, nb_classes = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(input_channels, nb_channels,\n",
    "                              kernel_size = kernel_size,\n",
    "                              padding = (kernel_size - 1) // 2)\n",
    "        self.bn = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "        self.resnet_blocks = nn.Sequential(\n",
    "            *(ResNetBlock(nb_channels, kernel_size)\n",
    "              for _ in range(nb_residual_blocks))\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(64, nb_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn(self.conv(x)))\n",
    "        x = self.resnet_blocks(x)\n",
    "        x = F.avg_pool2d(x, 8).view(x.size(0), -1)\n",
    "        x = torch.sigmoid(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76610"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet(nb_residual_blocks = 1, input_channels = 2, nb_channels = 64, kernel_size = 3, nb_classes = 2)\n",
    "# Calculate the number of parameters in the model\n",
    "count_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72536"
      ]
     },
     "execution_count": 745,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BaseNet()\n",
    "\n",
    "# Calculate the number of parameters in the model\n",
    "count_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72268"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SiameseBaseNet()\n",
    "\n",
    "# Calculate the number of parameters in the model\n",
    "count_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72268"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AuxsiameseBaseNet()\n",
    "\n",
    "# Calculate the number of parameters in the model\n",
    "count_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134766"
      ]
     },
     "execution_count": 748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AuxBaseNet()\n",
    "\n",
    "# Calculate the number of parameters in the model\n",
    "count_param(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, eta, decay, n_epochs=25, verbose=False, siamese=False, aux=False, alpha = 0):\n",
    "\n",
    "    #binary_crit = nn.CrossEntropyLoss()\n",
    "    binary_crit = torch.nn.BCELoss()\n",
    "    aux_crit = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=eta, weight_decay=decay)\n",
    "    \n",
    "    tr_losses = []\n",
    "    tr_accuracies = []\n",
    "\n",
    "    for e in range(n_epochs):\n",
    "        # Reset training/validation loss\n",
    "        tr_loss = 0\n",
    "\n",
    "        # Training model\n",
    "        model.train()\n",
    "\n",
    "        for train_input, train_target, train_classes in iter(train_loader):\n",
    "            train_target = torch.nn.functional.one_hot(train_target)\n",
    "            # Forward pass\n",
    "            \n",
    "            if siamese == True:\n",
    "                train_1, train_2 = train_input.unbind(1)\n",
    "                if aux == True:\n",
    "                    output, aux1, aux2 = model(train_1.unsqueeze(1), train_2.unsqueeze(1))\n",
    "                else:\n",
    "                    output = model(train_1.unsqueeze(1), train_2.unsqueeze(1))\n",
    "            elif aux == True:\n",
    "                train_1, train_2 = train_input.unbind(1)\n",
    "                output, aux1, aux2 = model(train_1.unsqueeze(1), train_2.unsqueeze(1))\n",
    "            else:\n",
    "                output = model(train_input)\n",
    "                \n",
    "            # Binary classification loss\n",
    "            binary_loss = binary_crit(output, train_target.float())\n",
    "            total_loss = binary_loss\n",
    "            \n",
    "            # Auxiliary loss\n",
    "            if aux == True:\n",
    "\n",
    "                aux_loss1 = aux_crit(aux1, train_classes[:,0])\n",
    "                aux_loss2 = aux_crit(aux2, train_classes[:,1])\n",
    "                aux_loss = aux_loss1 + aux_loss2\n",
    "                total_loss = binary_loss + aux_loss * alpha\n",
    "        \n",
    "            # Total loss = Binary loss + aux loss * alpha\n",
    "            \n",
    "            tr_loss += total_loss\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Collect accuracy data\n",
    "        # tr_accuracies.append(compute_nb_errors_siamese(model, train_loader)/1000)\n",
    "\n",
    "        # Collect loss data\n",
    "        tr_losses.append(tr_loss)\n",
    "\n",
    "        if verbose:\n",
    "            print('Epoch %d/%d, Binary loss: %.3f' %\n",
    "                  (e+1, n_epochs, tr_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Binary loss: 12.844\n",
      "Epoch 2/25, Binary loss: 10.807\n",
      "Epoch 3/25, Binary loss: 8.902\n",
      "Epoch 4/25, Binary loss: 7.213\n",
      "Epoch 5/25, Binary loss: 6.745\n",
      "Epoch 6/25, Binary loss: 5.449\n",
      "Epoch 7/25, Binary loss: 4.784\n",
      "Epoch 8/25, Binary loss: 5.199\n",
      "Epoch 9/25, Binary loss: 3.594\n",
      "Epoch 10/25, Binary loss: 2.876\n",
      "Epoch 11/25, Binary loss: 2.564\n",
      "Epoch 12/25, Binary loss: 2.030\n",
      "Epoch 13/25, Binary loss: 1.012\n",
      "Epoch 14/25, Binary loss: 1.100\n",
      "Epoch 15/25, Binary loss: 0.653\n",
      "Epoch 16/25, Binary loss: 0.295\n",
      "Epoch 17/25, Binary loss: 0.558\n",
      "Epoch 18/25, Binary loss: 0.729\n",
      "Epoch 19/25, Binary loss: 0.987\n",
      "Epoch 20/25, Binary loss: 1.280\n",
      "Epoch 21/25, Binary loss: 1.229\n",
      "Epoch 22/25, Binary loss: 1.010\n",
      "Epoch 23/25, Binary loss: 0.363\n",
      "Epoch 24/25, Binary loss: 0.325\n",
      "Epoch 25/25, Binary loss: 0.601\n",
      "Spend 2.450590e+02 s\n",
      "tensor(0.9870) tensor(0.8000)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "number = torch.randint(1,50,(1,))\n",
    "train_loader, test_loader = load_data(N=1000, batch_size=50, seed=number)\n",
    "time1 = time.perf_counter()\n",
    "#model = SiameseBaseNet()\n",
    "model = ResNet(nb_residual_blocks = 5, input_channels = 2, nb_channels = 64, kernel_size = 3, nb_classes = 2)\n",
    "train(model, train_loader, 0.001, 0, 25, verbose=True, siamese=False)\n",
    "time2 = time.perf_counter()\n",
    "print('Spend {:e} s'.format(time2 - time1))\n",
    "\n",
    "tr_accuracy = 1 - compute_nb_errors(model, train_loader)/1000\n",
    "te_accuracy = 1 - compute_nb_errors(model, test_loader)/1000\n",
    "print(tr_accuracy, te_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Binary loss: 2.743\n",
      "Epoch 2/25, Binary loss: 2.704\n",
      "Epoch 3/25, Binary loss: 2.636\n",
      "Epoch 4/25, Binary loss: 2.529\n",
      "Epoch 5/25, Binary loss: 2.372\n",
      "Epoch 6/25, Binary loss: 2.187\n",
      "Epoch 7/25, Binary loss: 1.991\n",
      "Epoch 8/25, Binary loss: 1.832\n",
      "Epoch 9/25, Binary loss: 1.687\n",
      "Epoch 10/25, Binary loss: 1.552\n",
      "Epoch 11/25, Binary loss: 1.421\n",
      "Epoch 12/25, Binary loss: 1.303\n",
      "Epoch 13/25, Binary loss: 1.189\n",
      "Epoch 14/25, Binary loss: 1.096\n",
      "Epoch 15/25, Binary loss: 1.001\n",
      "Epoch 16/25, Binary loss: 0.925\n",
      "Epoch 17/25, Binary loss: 0.836\n",
      "Epoch 18/25, Binary loss: 0.760\n",
      "Epoch 19/25, Binary loss: 0.696\n",
      "Epoch 20/25, Binary loss: 0.614\n",
      "Epoch 21/25, Binary loss: 0.548\n",
      "Epoch 22/25, Binary loss: 0.487\n",
      "Epoch 23/25, Binary loss: 0.422\n",
      "Epoch 24/25, Binary loss: 0.361\n",
      "Epoch 25/25, Binary loss: 0.307\n",
      "Spend 9.664215e+00 s\n",
      "tensor(0.9890) tensor(0.8580)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "number = torch.randint(1,50,(1,))\n",
    "train_loader, test_loader = load_data(N=1000, batch_size=250, seed=number)\n",
    "time1 = time.perf_counter()\n",
    "model = SiameseBaseNet()\n",
    "#model = BaseNet()\n",
    "train(model, train_loader, 0.001, 0, 25, verbose=True, siamese=True)\n",
    "time2 = time.perf_counter()\n",
    "print('Spend {:e} s'.format(time2 - time1))\n",
    "\n",
    "tr_accuracy = 1 - compute_nb_errors_siamese(model, train_loader)/1000\n",
    "te_accuracy = 1 - compute_nb_errors_siamese(model, test_loader)/1000\n",
    "print(tr_accuracy, te_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Binary loss: 2.775\n",
      "Epoch 2/25, Binary loss: 2.737\n",
      "Epoch 3/25, Binary loss: 2.680\n",
      "Epoch 4/25, Binary loss: 2.574\n",
      "Epoch 5/25, Binary loss: 2.400\n",
      "Epoch 6/25, Binary loss: 2.175\n",
      "Epoch 7/25, Binary loss: 1.978\n",
      "Epoch 8/25, Binary loss: 1.849\n",
      "Epoch 9/25, Binary loss: 1.777\n",
      "Epoch 10/25, Binary loss: 1.617\n",
      "Epoch 11/25, Binary loss: 1.531\n",
      "Epoch 12/25, Binary loss: 1.432\n",
      "Epoch 13/25, Binary loss: 1.335\n",
      "Epoch 14/25, Binary loss: 1.232\n",
      "Epoch 15/25, Binary loss: 1.146\n",
      "Epoch 16/25, Binary loss: 1.058\n",
      "Epoch 17/25, Binary loss: 0.955\n",
      "Epoch 18/25, Binary loss: 0.865\n",
      "Epoch 19/25, Binary loss: 0.781\n",
      "Epoch 20/25, Binary loss: 0.770\n",
      "Epoch 21/25, Binary loss: 0.651\n",
      "Epoch 22/25, Binary loss: 0.549\n",
      "Epoch 23/25, Binary loss: 0.616\n",
      "Epoch 24/25, Binary loss: 0.616\n",
      "Epoch 25/25, Binary loss: 0.484\n",
      "Spend 4.811039e+00 s\n",
      "tensor(0.9780) tensor(0.8450)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "number = torch.randint(1,50,(1,))\n",
    "train_loader, test_loader = load_data(N=1000, batch_size=50, seed=number)\n",
    "time1 = time.perf_counter()\n",
    "#modeF.avg_pool2dl = SiameseBaseNet()\n",
    "model = BaseNet()\n",
    "train(model, train_loader, 0.001, 0, 25, verbose=True, siamese=False)\n",
    "time2 = time.perf_counter()\n",
    "print('Spend {:e} s'.format(time2 - time1))\n",
    "\n",
    "tr_accuracy = 1 - compute_nb_errors(model, train_loader)/1000\n",
    "te_accuracy = 1 - compute_nb_errors(model, test_loader)/1000\n",
    "print(tr_accuracy, te_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-673-21efc383ef87>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux1 = F.softmax(x1)\n",
      "<ipython-input-673-21efc383ef87>:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux2 = F.softmax(x2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Binary loss: 41.301\n",
      "Epoch 2/25, Binary loss: 40.527\n",
      "Epoch 3/25, Binary loss: 39.194\n",
      "Epoch 4/25, Binary loss: 37.589\n",
      "Epoch 5/25, Binary loss: 35.413\n",
      "Epoch 6/25, Binary loss: 33.461\n",
      "Epoch 7/25, Binary loss: 32.224\n",
      "Epoch 8/25, Binary loss: 31.236\n",
      "Epoch 9/25, Binary loss: 30.435\n",
      "Epoch 10/25, Binary loss: 29.611\n",
      "Epoch 11/25, Binary loss: 29.025\n",
      "Epoch 12/25, Binary loss: 28.527\n",
      "Epoch 13/25, Binary loss: 28.140\n",
      "Epoch 14/25, Binary loss: 27.689\n",
      "Epoch 15/25, Binary loss: 27.367\n",
      "Epoch 16/25, Binary loss: 27.219\n",
      "Epoch 17/25, Binary loss: 27.102\n",
      "Epoch 18/25, Binary loss: 26.959\n",
      "Epoch 19/25, Binary loss: 26.890\n",
      "Epoch 20/25, Binary loss: 26.829\n",
      "Epoch 21/25, Binary loss: 26.785\n",
      "Epoch 22/25, Binary loss: 26.759\n",
      "Epoch 23/25, Binary loss: 26.788\n",
      "Epoch 24/25, Binary loss: 26.739\n",
      "Epoch 25/25, Binary loss: 26.726\n",
      "Spend 1.036312e+01 s\n",
      "tensor(1.) tensor(0.8700)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "number = torch.randint(1,50,(1,))\n",
    "train_loader, test_loader = load_data(N=1000, batch_size=50, seed=number)\n",
    "time1 = time.perf_counter()\n",
    "#model = SiameseBaseNet()\n",
    "#model = BaseNet()\n",
    "model = AuxsiameseBaseNet()\n",
    "train(model, train_loader, 0.001, 0, 25, verbose=True, siamese=True, aux=True, alpha = 0.3)\n",
    "time2 = time.perf_counter()\n",
    "print('Spend {:e} s'.format(time2 - time1))\n",
    "\n",
    "tr_accuracy = 1 - compute_nb_errors_auxsiamese(model, train_loader)/1000\n",
    "te_accuracy = 1 - compute_nb_errors_auxsiamese(model, test_loader)/1000\n",
    "print(tr_accuracy, te_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-699-f890ddbc2f26>:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux1 = F.softmax(x1)\n",
      "<ipython-input-699-f890ddbc2f26>:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux2 = F.softmax(x2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Binary loss: 41.354\n",
      "Epoch 2/25, Binary loss: 40.233\n",
      "Epoch 3/25, Binary loss: 38.545\n",
      "Epoch 4/25, Binary loss: 36.119\n",
      "Epoch 5/25, Binary loss: 34.638\n",
      "Epoch 6/25, Binary loss: 32.981\n",
      "Epoch 7/25, Binary loss: 32.049\n",
      "Epoch 8/25, Binary loss: 31.040\n",
      "Epoch 9/25, Binary loss: 30.221\n",
      "Epoch 10/25, Binary loss: 29.890\n",
      "Epoch 11/25, Binary loss: 29.816\n",
      "Epoch 12/25, Binary loss: 28.891\n",
      "Epoch 13/25, Binary loss: 28.312\n",
      "Epoch 14/25, Binary loss: 27.903\n",
      "Epoch 15/25, Binary loss: 27.736\n",
      "Epoch 16/25, Binary loss: 27.181\n",
      "Epoch 17/25, Binary loss: 26.733\n",
      "Epoch 18/25, Binary loss: 26.162\n",
      "Epoch 19/25, Binary loss: 26.032\n",
      "Epoch 20/25, Binary loss: 25.755\n",
      "Epoch 21/25, Binary loss: 25.475\n",
      "Epoch 22/25, Binary loss: 25.369\n",
      "Epoch 23/25, Binary loss: 25.333\n",
      "Epoch 24/25, Binary loss: 25.143\n",
      "Epoch 25/25, Binary loss: 25.044\n",
      "Spend 9.934680e+00 s\n",
      "tensor(1.) tensor(0.8390)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "number = torch.randint(1,50,(1,))\n",
    "train_loader, test_loader = load_data(N=1000, batch_size=50, seed=number)\n",
    "time1 = time.perf_counter()\n",
    "#model = SiameseBaseNet()\n",
    "#model = BaseNet()\n",
    "model = AuxBaseNet()\n",
    "train(model, train_loader, 0.001, 0, 25, verbose=True, siamese=False, aux=True, alpha = 0.3)\n",
    "time2 = time.perf_counter()\n",
    "print('Spend {:e} s'.format(time2 - time1))\n",
    "\n",
    "tr_accuracy = 1 - compute_nb_errors_auxsiamese(model, train_loader)/1000\n",
    "te_accuracy = 1 - compute_nb_errors_auxsiamese(model, test_loader)/1000\n",
    "print(tr_accuracy, te_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(0.8300)\n",
      "tensor(1.) tensor(0.8050)\n",
      "tensor(0.9900) tensor(0.8370)\n",
      "tensor(1.) tensor(0.8410)\n",
      "tensor(0.9950) tensor(0.8220)\n",
      "tensor(1.) tensor(0.8380)\n",
      "tensor(1.) tensor(0.8100)\n",
      "tensor(1.) tensor(0.8280)\n",
      "tensor(0.9990) tensor(0.8490)\n",
      "tensor(0.9990) tensor(0.8350)\n",
      "tensor(1.) tensor(0.8320)\n",
      "tensor(1.) tensor(0.8160)\n",
      "tensor(0.9990) tensor(0.8160)\n",
      "tensor(1.) tensor(0.8500)\n",
      "tensor(0.9990) tensor(0.8220)\n",
      "tensor(1.) tensor(0.7870)\n",
      "tensor(1.) tensor(0.8270)\n",
      "tensor(1.) tensor(0.8300)\n",
      "tensor(1.) tensor(0.8340)\n",
      "tensor(0.9700) tensor(0.8000)\n",
      "Mean: 0.825, Std: 0.016\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "times = []\n",
    "\n",
    "for i in range(20):\n",
    "    train_loader, test_loader = load_data(N=1000, batch_size=100, seed=i)\n",
    "    time1 = time.perf_counter()\n",
    "    #model = SiameseBaseNet()\n",
    "    model = BaseNet()\n",
    "    train(model, train_loader, 0.001, 0, 25, verbose=False, siamese=False)\n",
    "    time2 = time.perf_counter()\n",
    "    times.append(time2 - time1)\n",
    "\n",
    "    tr_accuracy = 1 - compute_nb_errors(model, train_loader)/1000\n",
    "    te_accuracy = 1 - compute_nb_errors(model, test_loader)/1000\n",
    "    print(tr_accuracy, te_accuracy)\n",
    "    accuracies.append(te_accuracy)\n",
    "\n",
    "print('Mean: %.3f, Std: %.3f' %(torch.tensor(accuracies).mean(), torch.tensor(accuracies).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(0.8480)\n",
      "tensor(1.) tensor(0.8780)\n",
      "tensor(1.) tensor(0.8430)\n",
      "tensor(1.) tensor(0.8650)\n",
      "tensor(1.) tensor(0.8710)\n",
      "tensor(1.) tensor(0.8520)\n",
      "tensor(1.) tensor(0.8710)\n",
      "tensor(1.) tensor(0.8340)\n",
      "tensor(1.) tensor(0.8590)\n",
      "tensor(1.) tensor(0.8500)\n",
      "tensor(1.) tensor(0.8520)\n",
      "tensor(1.) tensor(0.8330)\n",
      "tensor(1.) tensor(0.8440)\n",
      "tensor(1.) tensor(0.8680)\n",
      "tensor(1.) tensor(0.8520)\n",
      "tensor(1.) tensor(0.8560)\n",
      "tensor(1.) tensor(0.8510)\n",
      "tensor(1.) tensor(0.8670)\n",
      "tensor(1.) tensor(0.8540)\n",
      "tensor(1.) tensor(0.8600)\n",
      "Mean: 0.855, Std: 0.012\n"
     ]
    }
   ],
   "source": [
    "accuracies1 = []\n",
    "times1 = []\n",
    "\n",
    "for i in range(20):\n",
    "    train_loader, test_loader = load_data(N=1000, batch_size=50, seed=i)\n",
    "    time1 = time.perf_counter()\n",
    "    model = SiameseBaseNet()\n",
    "    #model = BaseNet()\n",
    "    train(model, train_loader, 0.001, 0, 25, verbose=False, siamese=True)\n",
    "    time2 = time.perf_counter()\n",
    "    times1.append(time2 - time1)\n",
    "\n",
    "    tr_accuracy = 1 - compute_nb_errors_siamese(model, train_loader)/1000\n",
    "    te_accuracy = 1 - compute_nb_errors_siamese(model, test_loader)/1000\n",
    "    print(tr_accuracy, te_accuracy)\n",
    "    accuracies1.append(te_accuracy)\n",
    "    \n",
    "print('Mean: %.3f, Std: %.3f' %(torch.tensor(accuracies1).mean(), torch.tensor(accuracies1).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-744-d08fd1651f1c>:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux1 = F.softmax(x1)\n",
      "<ipython-input-744-d08fd1651f1c>:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux2 = F.softmax(x2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9950) tensor(0.8380)\n",
      "tensor(0.9630) tensor(0.7950)\n",
      "tensor(1.) tensor(0.8470)\n",
      "tensor(1.) tensor(0.8250)\n",
      "tensor(1.) tensor(0.8450)\n",
      "tensor(0.9980) tensor(0.8370)\n",
      "tensor(1.) tensor(0.8270)\n",
      "tensor(1.) tensor(0.8470)\n",
      "tensor(0.9990) tensor(0.8550)\n",
      "tensor(1.) tensor(0.8240)\n",
      "tensor(1.) tensor(0.8500)\n",
      "tensor(0.9980) tensor(0.8490)\n",
      "tensor(1.) tensor(0.8440)\n",
      "tensor(1.) tensor(0.8310)\n",
      "tensor(0.9900) tensor(0.8070)\n",
      "tensor(1.) tensor(0.8320)\n",
      "tensor(1.) tensor(0.8330)\n",
      "tensor(0.9960) tensor(0.8400)\n",
      "tensor(0.9990) tensor(0.8660)\n",
      "tensor(0.9980) tensor(0.8050)\n",
      "Mean: 0.835, Std: 0.018\n"
     ]
    }
   ],
   "source": [
    "accuracies2 = []\n",
    "times2 = []\n",
    "\n",
    "for i in range(20):\n",
    "    train_loader, test_loader = load_data(N=1000, batch_size=50, seed=i)\n",
    "    time1 = time.perf_counter()\n",
    "    #model = SiameseBaseNet()\n",
    "    #model = BaseNet()\n",
    "    model = AuxBaseNet()\n",
    "    train(model, train_loader, 0.001, 0, 25, verbose=False, siamese=False, aux=True, alpha = 0.6)\n",
    "    time2 = time.perf_counter()\n",
    "    times2.append(time2 - time1)\n",
    "\n",
    "    tr_accuracy = 1 - compute_nb_errors_auxsiamese(model, train_loader)/1000\n",
    "    te_accuracy = 1 - compute_nb_errors_auxsiamese(model, test_loader)/1000\n",
    "    print(tr_accuracy, te_accuracy)\n",
    "    accuracies2.append(te_accuracy)\n",
    "    \n",
    "print('Mean: %.3f, Std: %.3f' %(torch.tensor(accuracies2).mean(), torch.tensor(accuracies2).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-743-f9afae9d6bc5>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux1 = F.softmax(x1)\n",
      "<ipython-input-743-f9afae9d6bc5>:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux2 = F.softmax(x2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(0.8680)\n",
      "tensor(1.) tensor(0.8770)\n",
      "tensor(0.9930) tensor(0.8510)\n",
      "tensor(1.) tensor(0.8780)\n",
      "tensor(1.) tensor(0.8700)\n",
      "tensor(1.) tensor(0.8490)\n",
      "tensor(1.) tensor(0.8650)\n",
      "tensor(1.) tensor(0.8530)\n",
      "tensor(0.9970) tensor(0.8710)\n",
      "tensor(0.9960) tensor(0.8590)\n",
      "tensor(1.) tensor(0.8560)\n",
      "tensor(1.) tensor(0.8470)\n",
      "tensor(0.9990) tensor(0.8580)\n",
      "tensor(1.) tensor(0.8650)\n",
      "tensor(1.) tensor(0.8640)\n",
      "tensor(1.) tensor(0.8690)\n",
      "tensor(1.) tensor(0.8590)\n",
      "tensor(1.) tensor(0.8610)\n",
      "tensor(1.) tensor(0.8540)\n",
      "tensor(1.) tensor(0.8620)\n",
      "Mean: 0.862, Std: 0.009\n"
     ]
    }
   ],
   "source": [
    "accuracies3 = []\n",
    "times3 = []\n",
    "\n",
    "for i in range(20):\n",
    "    train_loader, test_loader = load_data(N=1000, batch_size=50, seed=i)\n",
    "    time1 = time.perf_counter()\n",
    "    #model = SiameseBaseNet()\n",
    "    #model = BaseNet()\n",
    "    model = AuxsiameseBaseNet()\n",
    "    train(model, train_loader, 0.001, 0, 25, verbose=False, siamese=True, aux=True)\n",
    "    time2 = time.perf_counter()\n",
    "    times3.append(time2 - time1)\n",
    "\n",
    "    tr_accuracy = 1 - compute_nb_errors_auxsiamese(model, train_loader)/1000\n",
    "    te_accuracy = 1 - compute_nb_errors_auxsiamese(model, test_loader)/1000\n",
    "    print(tr_accuracy, te_accuracy)\n",
    "    accuracies3.append(te_accuracy)\n",
    "    \n",
    "print('Mean: %.3f, Std: %.3f' %(torch.tensor(accuracies3).mean(), torch.tensor(accuracies3).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(0.8260)\n",
      "tensor(1.) tensor(0.8340)\n",
      "tensor(1.) tensor(0.8040)\n",
      "tensor(1.) tensor(0.8090)\n",
      "tensor(1.) tensor(0.8390)\n",
      "tensor(1.) tensor(0.8310)\n",
      "tensor(0.9990) tensor(0.8360)\n",
      "tensor(1.) tensor(0.8570)\n",
      "tensor(1.) tensor(0.8220)\n",
      "tensor(0.9990) tensor(0.8730)\n",
      "tensor(1.) tensor(0.8300)\n",
      "tensor(1.) tensor(0.8360)\n",
      "tensor(1.) tensor(0.8400)\n",
      "tensor(1.) tensor(0.8220)\n",
      "tensor(0.9970) tensor(0.8240)\n",
      "tensor(0.9990) tensor(0.8270)\n",
      "tensor(0.9990) tensor(0.8320)\n",
      "tensor(1.) tensor(0.8350)\n",
      "tensor(1.) tensor(0.8320)\n",
      "tensor(1.) tensor(0.8190)\n",
      "Mean: 0.831, Std: 0.015\n"
     ]
    }
   ],
   "source": [
    "accuracies4 = []\n",
    "times4 = []\n",
    "\n",
    "for i in range(20):\n",
    "    train_loader, test_loader = load_data(N=1000, batch_size=50, seed=i)\n",
    "    time1 = time.perf_counter()\n",
    "    #model = SiameseBaseNet()\n",
    "    #model = BaseNet()\n",
    "    model = ResNet(nb_residual_blocks = 1, input_channels = 2, nb_channels = 32, kernel_size = 3, nb_classes = 2)\n",
    "    train(model, train_loader, 0.001, 0, 25, verbose=False, siamese=False)\n",
    "    time2 = time.perf_counter()\n",
    "    times4.append(time2 - time1)\n",
    "\n",
    "    tr_accuracy = 1 - compute_nb_errors(model, train_loader)/1000\n",
    "    te_accuracy = 1 - compute_nb_errors(model, test_loader)/1000\n",
    "    print(tr_accuracy, te_accuracy)\n",
    "    accuracies4.append(te_accuracy)\n",
    "    \n",
    "print('Mean: %.3f, Std: %.3f' %(torch.tensor(accuracies4).mean(), torch.tensor(accuracies4).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-419-1ee55fdbefe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgammas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mte_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcompute_nb_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0maccurate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mte_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-405-c75a86d473c7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, eta, decay, n_epochs, verbose)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mbinary_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Collect accuracy data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gammas = torch.logspace(start=-4, end=-2, steps=5)\n",
    "decays = torch.logspace(start=-13, end=-8, steps=6)\n",
    "accuracies = torch.empty((len(gammas), len(decays)))\n",
    "model = BaseNet()\n",
    "for j in range(len(gammas)):\n",
    "    for k in range(len(decays)):\n",
    "        accurate = []\n",
    "        for i in range(10):\n",
    "            train_loader, test_loader = load_data(N=1000, batch_size=50, seed=42)\n",
    "            train(model, train_loader, gammas[j], decays[k], 25, verbose=False)\n",
    "            te_accuracy = 1 - compute_nb_errors(model, test_loader)/1000\n",
    "            accurate.append(te_accuracy)\n",
    "        accuracies[j,k] = torch.Tensor(accurate).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-744-d08fd1651f1c>:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux1 = F.softmax(x1)\n",
      "<ipython-input-744-d08fd1651f1c>:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux2 = F.softmax(x2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.833, Std: 0.009\n",
      "Mean: 0.831, Std: 0.008\n",
      "Mean: 0.819, Std: 0.047\n",
      "Mean: 0.834, Std: 0.008\n",
      "Mean: 0.830, Std: 0.013\n",
      "Mean: 0.833, Std: 0.010\n",
      "Mean: 0.835, Std: 0.018\n",
      "Mean: 0.833, Std: 0.014\n",
      "Mean: 0.833, Std: 0.014\n",
      "Mean: 0.833, Std: 0.017\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    accuracies3 = []\n",
    "    times3 = []\n",
    "\n",
    "    for i in range(10):\n",
    "        train_loader, test_loader = load_data(N=1000, batch_size=50, seed=i)\n",
    "        time1 = time.perf_counter()\n",
    "        #model = SiameseBaseNet()\n",
    "        #model = BaseNet()\n",
    "        model = AuxBaseNet()\n",
    "        train(model, train_loader, 0.001, 0, 25, verbose=False, siamese=False, aux=True, alpha = j/10)\n",
    "        time2 = time.perf_counter()\n",
    "        times3.append(time2 - time1)\n",
    "\n",
    "        tr_accuracy = 1 - compute_nb_errors_auxsiamese(model, train_loader)/1000\n",
    "        te_accuracy = 1 - compute_nb_errors_auxsiamese(model, test_loader)/1000\n",
    "        accuracies3.append(te_accuracy)\n",
    "    print('Mean: %.3f, Std: %.3f' %(torch.tensor(accuracies3).mean(), torch.tensor(accuracies3).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-743-f9afae9d6bc5>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux1 = F.softmax(x1)\n",
      "<ipython-input-743-f9afae9d6bc5>:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux2 = F.softmax(x2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.860, Std: 0.015\n",
      "Mean: 0.859, Std: 0.011\n",
      "Mean: 0.858, Std: 0.012\n",
      "Mean: 0.857, Std: 0.011\n",
      "Mean: 0.861, Std: 0.010\n",
      "Mean: 0.864, Std: 0.011\n",
      "Mean: 0.859, Std: 0.011\n",
      "Mean: 0.857, Std: 0.017\n",
      "Mean: 0.859, Std: 0.018\n",
      "Mean: 0.859, Std: 0.022\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    accuracies2 = []\n",
    "    times2 = []\n",
    "\n",
    "    for i in range(10):\n",
    "        train_loader, test_loader = load_data(N=1000, batch_size=50, seed=i)\n",
    "        time1 = time.perf_counter()\n",
    "        #model = SiameseBaseNet()\n",
    "        #model = BaseNet()\n",
    "        model = AuxsiameseBaseNet()\n",
    "        train(model, train_loader, 0.001, 0, 25, verbose=False, siamese=True, aux=True, alpha = j/10)\n",
    "        time2 = time.perf_counter()\n",
    "        times2.append(time2 - time1)\n",
    "\n",
    "        tr_accuracy = 1 - compute_nb_errors_auxsiamese(model, train_loader)/1000\n",
    "        te_accuracy = 1 - compute_nb_errors_auxsiamese(model, test_loader)/1000\n",
    "        accuracies2.append(te_accuracy)\n",
    "    print('Mean: %.3f, Std: %.3f' %(torch.tensor(accuracies2).mean(), torch.tensor(accuracies2).std())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-673-21efc383ef87>:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux1 = F.softmax(x1)\n",
      "<ipython-input-673-21efc383ef87>:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  aux2 = F.softmax(x2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.851, Std: 0.013\n",
      "Mean: 0.852, Std: 0.023\n",
      "Mean: 0.851, Std: 0.021\n",
      "Mean: 0.852, Std: 0.019\n",
      "Mean: 0.855, Std: 0.021\n",
      "Mean: 0.849, Std: 0.027\n",
      "Mean: 0.843, Std: 0.038\n",
      "Mean: 0.835, Std: 0.054\n",
      "Mean: 0.852, Std: 0.036\n",
      "Mean: 0.830, Std: 0.054\n"
     ]
    }
   ],
   "source": [
    "for j in range(10,20):\n",
    "    accuracies2 = []\n",
    "    times2 = []\n",
    "\n",
    "    for i in range(10):\n",
    "        train_loader, test_loader = load_data(N=1000, batch_size=50, seed=i)\n",
    "        time1 = time.perf_counter()\n",
    "        #model = SiameseBaseNet()\n",
    "        #model = BaseNet()\n",
    "        model = AuxsiameseBaseNet()\n",
    "        train(model, train_loader, 0.001, 0, 25, verbose=False, siamese=True, aux=True, alpha = j/10)\n",
    "        time2 = time.perf_counter()\n",
    "        times2.append(time2 - time1)\n",
    "\n",
    "        tr_accuracy = 1 - compute_nb_errors_auxsiamese(model, train_loader)/1000\n",
    "        te_accuracy = 1 - compute_nb_errors_auxsiamese(model, test_loader)/1000\n",
    "        accuracies2.append(te_accuracy)\n",
    "    print('Mean: %.3f, Std: %.3f' %(torch.tensor(accuracies2).mean(), torch.tensor(accuracies2).std())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
