{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import dlc_practical_prologue as prologue\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\jizhu\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from MLP_models import *\n",
    "from CNN_models import *\n",
    "from Resnet_models import *\n",
    "from helpers import *\n",
    "from data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of parameters of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters in model_1 is 73314\n",
      "The number of parameters in model_2 is 33172\n",
      "The number of parameters in model_3 is 66302\n",
      "The number of parameters in model_4 is 33172\n",
      "The number of parameters in model_5 is 72536\n",
      "The number of parameters in model_6 is 72268\n",
      "The number of parameters in model_7 is 144494\n",
      "The number of parameters in model_8 is 72268\n",
      "The number of parameters in model_9 is 75746\n",
      "The number of parameters in model_10 is 77812\n",
      "The number of parameters in model_11 is 152692\n",
      "The number of parameters in model_12 is 77812\n"
     ]
    }
   ],
   "source": [
    "model_1 = MLP()\n",
    "model_2 = SiameseMLP()\n",
    "model_3 = AuxMLP()\n",
    "model_4 = AuxsiameseMLP()\n",
    "model_5 = CNN()\n",
    "model_6 = SiameseCNN()\n",
    "model_7 = AuxCNN()\n",
    "model_8 = AuxsiameseCNN()\n",
    "model_9 = ResNet()\n",
    "model_10 = SiameseResNet()\n",
    "model_11 = AuxResNet()\n",
    "model_12 = AuxsiameseResNet()\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5, model_6, model_7, model_8, model_9, model_10, model_11, model_12]\n",
    "for i in range(len(models)):\n",
    "    #print('The number of parameters in' count_param(i))\n",
    "    print('The number of parameters in model_%d is %d' %\n",
    "                  (i+1, count_param(models[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, eta, decay, n_epochs=25, verbose=False, siamese=False, aux=False, alpha = 0):\n",
    "    '''\n",
    "    model: learning model\n",
    "    '''\n",
    "    binary_crit = torch.nn.BCELoss()\n",
    "    aux_crit = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=eta, weight_decay=decay)\n",
    "    tr_losses = []\n",
    "    tr_accuracies = []\n",
    "\n",
    "    for e in range(n_epochs):\n",
    "        # Reset training/validation loss\n",
    "        tr_loss = 0\n",
    "\n",
    "        # Training model\n",
    "        model.train()\n",
    "\n",
    "        for train_input, train_target, train_classes in iter(train_loader):\n",
    "            \n",
    "            # Forward pass\n",
    "            if aux == True:\n",
    "                train_1, train_2 = train_input.unbind(1)\n",
    "                output, aux1, aux2 = model(train_1.unsqueeze(1), train_2.unsqueeze(1))\n",
    "                \n",
    "            elif siamese == True:\n",
    "                train_1, train_2 = train_input.unbind(1)\n",
    "                output = model(train_1.unsqueeze(1), train_2.unsqueeze(1))\n",
    "                \n",
    "            else:\n",
    "                output = model(train_input)\n",
    "                \n",
    "            # Binary classification loss\n",
    "            binary_loss = binary_crit(output, train_target.float())\n",
    "            total_loss = binary_loss\n",
    "            \n",
    "            # Auxiliary loss\n",
    "            if aux == True:\n",
    "\n",
    "                aux_loss1 = aux_crit(aux1, train_classes[:,0])\n",
    "                aux_loss2 = aux_crit(aux2, train_classes[:,1])\n",
    "                aux_loss = aux_loss1 + aux_loss2\n",
    "                \n",
    "                # Total loss = Binary loss + aux loss * alpha\n",
    "                total_loss = binary_loss + aux_loss * alpha\n",
    "            \n",
    "            tr_loss += float(total_loss)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Collect loss data\n",
    "        tr_losses.append(tr_loss)\n",
    "\n",
    "        if verbose:\n",
    "            print('Epoch %d/%d, Binary loss: %.3f' %\n",
    "                  (e+1, n_epochs, tr_loss))\n",
    "    return tr_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(model, train_loader, test_loader, siamese = False, aux = False):\n",
    "    \n",
    "    if aux == True:\n",
    "        tr_accuracy = 1 - compute_nb_errors_auxsiamese(model, train_loader)/1000\n",
    "        te_accuracy = 1 - compute_nb_errors_auxsiamese(model, test_loader)/1000\n",
    "    elif siamese == True:\n",
    "        tr_accuracy = 1 - compute_nb_errors_siamese(model, train_loader)/1000\n",
    "        te_accuracy = 1 - compute_nb_errors_siamese(model, test_loader)/1000\n",
    "    else:\n",
    "        tr_accuracy = 1 - compute_nb_errors(model, train_loader)/1000\n",
    "        te_accuracy = 1 - compute_nb_errors(model, test_loader)/1000\n",
    "            \n",
    "    return tr_accuracy, te_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune learning rate and batch size for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_model = [[MLP, False, False],\n",
    "              [SiameseMLP, True, False],\n",
    "              [AuxMLP, False, True],\n",
    "              [AuxsiameseMLP, True, True],\n",
    "              [CNN, False, False],\n",
    "              [SiameseCNN, True, False],\n",
    "              [AuxCNN, False, True],\n",
    "              [AuxsiameseCNN, True, True],\n",
    "              [ResNet, False, False],\n",
    "              [SiameseResNet, True, False],\n",
    "              [AuxResNet, False, True],\n",
    "              [AuxsiameseResNet, True, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal parameters for model_1: learning rate 0.00100, batch size: 16\n",
      "The optimal parameters for model_2: learning rate 0.00500, batch size: 8\n",
      "The optimal parameters for model_3: learning rate 0.00500, batch size: 32\n",
      "The optimal parameters for model_4: learning rate 0.00500, batch size: 8\n",
      "The optimal parameters for model_5: learning rate 0.00050, batch size: 8\n",
      "The optimal parameters for model_6: learning rate 0.00050, batch size: 128\n",
      "The optimal parameters for model_7: learning rate 0.00100, batch size: 32\n",
      "The optimal parameters for model_8: learning rate 0.00050, batch size: 128\n",
      "The optimal parameters for model_9: learning rate 0.00100, batch size: 32\n",
      "The optimal parameters for model_10: learning rate 0.00500, batch size: 8\n",
      "The optimal parameters for model_11: learning rate 0.00100, batch size: 8\n",
      "The optimal parameters for model_12: learning rate 0.00500, batch size: 8\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "std = []\n",
    "model_number = 0\n",
    "for models in Train_model:\n",
    "    gammas = [5e-3, 1e-3, 5e-4, 1e-4]\n",
    "    batch_sizes = [8, 16, 32, 64, 128]\n",
    "    test_accuracies = torch.empty((len(gammas), len(batch_sizes)))\n",
    "    test_stds = torch.empty((len(gammas), len(batch_sizes)))\n",
    "\n",
    "    for j in range(len(gammas)):\n",
    "        for k in range(len(batch_sizes)):\n",
    "            accurate = []\n",
    "            for i in range(10):\n",
    "                model = models[0]()\n",
    "                model.to(device)\n",
    "                train_loader, test_loader = load_data(N=1000, batch_size=batch_sizes[k], seed=i)\n",
    "                loss = train(model, train_loader, gammas[j], 0, 25, verbose=False, siamese=models[1], aux=models[2])\n",
    "                tr_accuracy, te_accuracy = accu(model, train_loader, test_loader, siamese=models[1], aux=models[2])\n",
    "                accurate.append(te_accuracy)\n",
    "            test_accuracies[j,k] =  torch.FloatTensor(accurate).mean()\n",
    "            test_stds[j,k] =  torch.FloatTensor(accurate).std()\n",
    "    accuracy.append(test_accuracies)\n",
    "    std.append(test_stds)\n",
    "    max_index = test_accuracies.argmax() \n",
    "    model_number += 1\n",
    "    print('The optimal parameters for model_%d: learning rate %.5f, batch size: %d' %(model_number, gammas[(max_index)//5], batch_sizes[(max_index+1)%5-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.8028, 0.8028, 0.8011, 0.7980, 0.8034],\n",
       "         [0.8052, 0.8087, 0.8048, 0.8018, 0.8023],\n",
       "         [0.8053, 0.8040, 0.8033, 0.8020, 0.7962],\n",
       "         [0.7955, 0.7924, 0.7864, 0.7810, 0.7700]]),\n",
       " tensor([[0.8450, 0.8439, 0.8443, 0.8428, 0.8395],\n",
       "         [0.8398, 0.8373, 0.8358, 0.8313, 0.8309],\n",
       "         [0.8371, 0.8346, 0.8335, 0.8298, 0.8136],\n",
       "         [0.8200, 0.8132, 0.8003, 0.7841, 0.7601]]),\n",
       " tensor([[0.8176, 0.8136, 0.8179, 0.8141, 0.8142],\n",
       "         [0.8148, 0.8105, 0.8099, 0.8053, 0.8041],\n",
       "         [0.8100, 0.8112, 0.8076, 0.8018, 0.7954],\n",
       "         [0.7969, 0.7868, 0.7751, 0.7666, 0.7541]]),\n",
       " tensor([[0.8450, 0.8439, 0.8443, 0.8428, 0.8395],\n",
       "         [0.8398, 0.8373, 0.8358, 0.8313, 0.8309],\n",
       "         [0.8371, 0.8346, 0.8335, 0.8298, 0.8136],\n",
       "         [0.8200, 0.8132, 0.8003, 0.7841, 0.7601]]),\n",
       " tensor([[0.7928, 0.8029, 0.7966, 0.7924, 0.8143],\n",
       "         [0.8269, 0.8314, 0.8297, 0.8336, 0.8243],\n",
       "         [0.8347, 0.8330, 0.8296, 0.8322, 0.8221],\n",
       "         [0.8282, 0.8219, 0.8098, 0.7900, 0.7602]]),\n",
       " tensor([[0.7904, 0.8152, 0.8157, 0.7869, 0.8487],\n",
       "         [0.8253, 0.8538, 0.8542, 0.8269, 0.8582],\n",
       "         [0.8572, 0.8581, 0.8588, 0.8588, 0.8626],\n",
       "         [0.8597, 0.8603, 0.8521, 0.8361, 0.7963]]),\n",
       " tensor([[0.7028, 0.6734, 0.7338, 0.7805, 0.7912],\n",
       "         [0.8278, 0.8313, 0.8376, 0.8311, 0.8285],\n",
       "         [0.8317, 0.8325, 0.8317, 0.8342, 0.8262],\n",
       "         [0.8322, 0.8275, 0.8224, 0.8100, 0.7891]]),\n",
       " tensor([[0.7904, 0.8152, 0.8157, 0.7869, 0.8487],\n",
       "         [0.8253, 0.8538, 0.8542, 0.8269, 0.8582],\n",
       "         [0.8572, 0.8581, 0.8588, 0.8588, 0.8626],\n",
       "         [0.8597, 0.8603, 0.8521, 0.8361, 0.7963]]),\n",
       " tensor([[0.8366, 0.8228, 0.8299, 0.8226, 0.8185],\n",
       "         [0.8382, 0.8403, 0.8404, 0.8344, 0.8262],\n",
       "         [0.8309, 0.8316, 0.8270, 0.8261, 0.8196],\n",
       "         [0.8173, 0.8134, 0.8130, 0.8156, 0.8164]]),\n",
       " tensor([[0.8798, 0.8417, 0.8390, 0.8421, 0.8361],\n",
       "         [0.8740, 0.8775, 0.8701, 0.8683, 0.8575],\n",
       "         [0.8685, 0.8643, 0.8630, 0.8519, 0.8399],\n",
       "         [0.8389, 0.8374, 0.8351, 0.8354, 0.8378]]),\n",
       " tensor([[0.7555, 0.8261, 0.8365, 0.8107, 0.8309],\n",
       "         [0.8511, 0.8475, 0.8444, 0.8398, 0.8313],\n",
       "         [0.8424, 0.8457, 0.8398, 0.8275, 0.8222],\n",
       "         [0.8219, 0.8177, 0.8143, 0.8154, 0.8266]]),\n",
       " tensor([[0.8798, 0.8417, 0.8390, 0.8421, 0.8361],\n",
       "         [0.8740, 0.8775, 0.8701, 0.8683, 0.8575],\n",
       "         [0.8685, 0.8643, 0.8630, 0.8519, 0.8399],\n",
       "         [0.8389, 0.8374, 0.8351, 0.8354, 0.8378]])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.0121, 0.0104, 0.0113, 0.0159, 0.0098],\n",
       "         [0.0086, 0.0117, 0.0091, 0.0130, 0.0117],\n",
       "         [0.0097, 0.0106, 0.0093, 0.0128, 0.0129],\n",
       "         [0.0138, 0.0105, 0.0157, 0.0163, 0.0138]]),\n",
       " tensor([[0.0163, 0.0200, 0.0185, 0.0178, 0.0206],\n",
       "         [0.0207, 0.0215, 0.0201, 0.0184, 0.0198],\n",
       "         [0.0178, 0.0189, 0.0205, 0.0200, 0.0165],\n",
       "         [0.0172, 0.0110, 0.0105, 0.0138, 0.0169]]),\n",
       " tensor([[0.0125, 0.0179, 0.0176, 0.0108, 0.0142],\n",
       "         [0.0110, 0.0116, 0.0103, 0.0118, 0.0115],\n",
       "         [0.0114, 0.0110, 0.0117, 0.0137, 0.0145],\n",
       "         [0.0128, 0.0151, 0.0129, 0.0130, 0.0151]]),\n",
       " tensor([[0.0163, 0.0200, 0.0185, 0.0178, 0.0206],\n",
       "         [0.0207, 0.0215, 0.0201, 0.0184, 0.0198],\n",
       "         [0.0178, 0.0189, 0.0205, 0.0200, 0.0165],\n",
       "         [0.0172, 0.0110, 0.0105, 0.0138, 0.0169]]),\n",
       " tensor([[0.0248, 0.0207, 0.0219, 0.0881, 0.0211],\n",
       "         [0.0117, 0.0112, 0.0124, 0.0110, 0.0144],\n",
       "         [0.0106, 0.0174, 0.0177, 0.0104, 0.0127],\n",
       "         [0.0117, 0.0093, 0.0097, 0.0168, 0.0153]]),\n",
       " tensor([[0.1295, 0.0907, 0.0922, 0.1179, 0.0109],\n",
       "         [0.0991, 0.0125, 0.0116, 0.0995, 0.0112],\n",
       "         [0.0103, 0.0132, 0.0123, 0.0133, 0.0127],\n",
       "         [0.0113, 0.0137, 0.0118, 0.0079, 0.0105]]),\n",
       " tensor([[0.1207, 0.0976, 0.1008, 0.0647, 0.0734],\n",
       "         [0.0139, 0.0109, 0.0099, 0.0115, 0.0086],\n",
       "         [0.0137, 0.0094, 0.0118, 0.0107, 0.0090],\n",
       "         [0.0111, 0.0096, 0.0098, 0.0147, 0.0173]]),\n",
       " tensor([[0.1295, 0.0907, 0.0922, 0.1179, 0.0109],\n",
       "         [0.0991, 0.0125, 0.0116, 0.0995, 0.0112],\n",
       "         [0.0103, 0.0132, 0.0123, 0.0133, 0.0127],\n",
       "         [0.0113, 0.0137, 0.0118, 0.0079, 0.0105]]),\n",
       " tensor([[0.0122, 0.0207, 0.0163, 0.0097, 0.0112],\n",
       "         [0.0127, 0.0123, 0.0128, 0.0138, 0.0133],\n",
       "         [0.0119, 0.0111, 0.0119, 0.0143, 0.0161],\n",
       "         [0.0120, 0.0101, 0.0093, 0.0078, 0.0132]]),\n",
       " tensor([[0.0136, 0.1036, 0.1056, 0.1004, 0.1032],\n",
       "         [0.0157, 0.0128, 0.0120, 0.0102, 0.0128],\n",
       "         [0.0112, 0.0262, 0.0111, 0.0122, 0.0207],\n",
       "         [0.0116, 0.0147, 0.0137, 0.0130, 0.0164]]),\n",
       " tensor([[0.1207, 0.0885, 0.0252, 0.0969, 0.0356],\n",
       "         [0.0125, 0.0117, 0.0172, 0.0178, 0.0188],\n",
       "         [0.0147, 0.0171, 0.0161, 0.0129, 0.0138],\n",
       "         [0.0105, 0.0190, 0.0120, 0.0152, 0.0122]]),\n",
       " tensor([[0.0136, 0.1036, 0.1056, 0.1004, 0.1032],\n",
       "         [0.0157, 0.0128, 0.0120, 0.0102, 0.0128],\n",
       "         [0.0112, 0.0262, 0.0111, 0.0122, 0.0207],\n",
       "         [0.0116, 0.0147, 0.0137, 0.0130, 0.0164]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune alpha for models with auxiliary loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_auxmodel = [[AuxMLP, False, True, 5e-3, 16],\n",
    "              [AuxsiameseMLP, True, True, 5e-3, 8],\n",
    "              [AuxCNN, False, True, 5e-4, 8],\n",
    "              [AuxsiameseCNN, True, True, 5e-3, 32],\n",
    "              [AuxResNet, False, True, 1e-3, 8],\n",
    "              [AuxsiameseResNet, True, True, 5e-3, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal alpha for aux_model_1 is 1.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-2d3b2662a714>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msiamese\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mtr_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msiamese\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0maccurate_aux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f6690593f659>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, eta, decay, n_epochs, verbose, siamese, aux, alpha)\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;31m# Collect loss data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'betas'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_aux = []\n",
    "std_aux = []\n",
    "model_number_aux = 0\n",
    "for models in Train_auxmodel:\n",
    "    test_accuracies_aux = torch.empty((1, 11))\n",
    "    test_stds_aux = torch.empty((1,11))    \n",
    "    for j in range(11):\n",
    "        accurate_aux = []\n",
    "        for i in range(10):\n",
    "            model = models[0]()\n",
    "            model.to(device)\n",
    "            \n",
    "            train_loader, test_loader = load_data(N=1000, batch_size = models[4], seed=i)\n",
    "            loss = train(model, train_loader, models[3], 0, 25, verbose=False, siamese=models[1], aux=models[2], alpha = j/10)\n",
    "            tr_accuracy, te_accuracy = accu(model, train_loader, test_loader, siamese=models[1], aux=models[2])\n",
    "            accurate_aux.append(te_accuracy)\n",
    "            \n",
    "        test_accuracies_aux[0,j] =  torch.FloatTensor(accurate_aux).mean()\n",
    "        test_stds_aux[0,j] =  torch.FloatTensor(accurate_aux).std()\n",
    "    accuracy_aux.append(test_accuracies_aux)\n",
    "    std_aux.append(test_stds_aux)\n",
    "    max_index = test_accuracies_aux.argmax() \n",
    "    model_number_aux += 1\n",
    "    print('The optimal alpha for aux_model_%d is %.2f' %(model_number_aux, max_index/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_final_model = [[MLP, False, False, 5e-4, 8, 0],\n",
    "              [SiameseMLP, True, False, 5e-3, 8, 0],\n",
    "              [AuxMLP, False, True, 5e-3, 16, 0.9],\n",
    "              [AuxsiameseMLP, True, True, 5e-3, 8, 0.7],\n",
    "              [CNN, False, False, 5e-4, 16, 0],\n",
    "              [SiameseCNN, True, False, 1e-3, 16, 0],\n",
    "              [AuxCNN, False, True, 5e-4, 8, 1.0],\n",
    "              [AuxsiameseCNN, True, True, 5e-3, 32, 0.6],\n",
    "              [ResNet, False, False, 1e-3, 32, 0],\n",
    "              [SiameseResNet, True, False, 5e-3, 32, 0],\n",
    "              [AuxResNet, False, True, 5e-3, 32, 0.6],\n",
    "              [AuxsiameseResNet, True, True, 5e-3, 32, 0.6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For optimal model_1, Mean accuracy: 0.810, Std: 0.010, Mean time: 10.164, Std: 0.613\n",
      "For optimal model_2, Mean accuracy: 0.814, Std: 0.101, Mean time: 6.424, Std: 0.637\n",
      "For optimal model_3, Mean accuracy: 0.849, Std: 0.017, Mean time: 8.898, Std: 0.570\n",
      "For optimal model_4, Mean accuracy: 0.876, Std: 0.021, Mean time: 6.860, Std: 0.685\n",
      "For optimal model_5, Mean accuracy: 0.825, Std: 0.021, Mean time: 11.122, Std: 0.800\n",
      "For optimal model_6, Mean accuracy: 0.823, Std: 0.098, Mean time: 16.943, Std: 1.064\n",
      "For optimal model_7, Mean accuracy: 0.871, Std: 0.009, Mean time: 38.943, Std: 1.508\n",
      "For optimal model_8, Mean accuracy: 0.903, Std: 0.017, Mean time: 9.981, Std: 0.968\n",
      "For optimal model_9, Mean accuracy: 0.835, Std: 0.011, Mean time: 26.725, Std: 1.541\n",
      "For optimal model_10, Mean accuracy: 0.807, Std: 0.137, Mean time: 47.060, Std: 2.568\n",
      "For optimal model_11, Mean accuracy: 0.878, Std: 0.025, Mean time: 52.441, Std: 3.036\n",
      "For optimal model_12, Mean accuracy: 0.905, Std: 0.016, Mean time: 50.276, Std: 1.513\n"
     ]
    }
   ],
   "source": [
    "loss_total = []\n",
    "index = 0\n",
    "for models in Train_final_model:\n",
    "    times = []\n",
    "    accuracies = []\n",
    "    losses = torch.empty((10,25))\n",
    "\n",
    "    for i in range(10):\n",
    "        train_loader, test_loader = load_data(N=1000, batch_size=models[4], seed=i)\n",
    "        time1 = time.perf_counter()\n",
    "\n",
    "        model = models[0]()\n",
    "        model.to(device)\n",
    "        losses[i,:] = torch.tensor(train(model, train_loader, models[3], 0, 25, verbose=False, siamese=models[1], aux=models[2], alpha = models[5]))\n",
    "        time2 = time.perf_counter()\n",
    "        times.append(time2 - time1)\n",
    "\n",
    "        tr_accuracy, te_accuracy = accu(model, train_loader, test_loader, siamese=models[1], aux=models[2])\n",
    "\n",
    "        accuracies.append(te_accuracy)\n",
    "    loss_total.append(losses)\n",
    "    index += 1\n",
    "    \n",
    "    print('For optimal model_%d, Mean accuracy: %.3f, Std: %.3f, Mean time: %.3f, Std: %.3f' %(index, torch.tensor(accuracies).mean(), torch.tensor(accuracies).std(), torch.tensor(times).mean(), torch.tensor(times).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For optimal model_1, Mean accuracy: 0.808, Std: 0.010, Mean time: 10.724, Std: 1.155\n",
      "For optimal model_2, Mean accuracy: 0.814, Std: 0.101, Mean time: 6.483, Std: 0.751\n",
      "For optimal model_3, Mean accuracy: 0.849, Std: 0.017, Mean time: 9.822, Std: 1.106\n",
      "For optimal model_4, Mean accuracy: 0.876, Std: 0.021, Mean time: 6.507, Std: 0.149\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-2bd3efd1a86a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mlosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msiamese\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mtime2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mtimes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f6690593f659>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, eta, decay, n_epochs, verbose, siamese, aux, alpha)\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_total = []\n",
    "index = 0\n",
    "for models in Train_final_model:\n",
    "    times = []\n",
    "    accuracies = []\n",
    "    losses = torch.empty((10,25))\n",
    "\n",
    "    for i in range(10):\n",
    "        train_loader, test_loader = load_data(N=1000, batch_size=models[4], seed=i)\n",
    "        time1 = time.perf_counter()\n",
    "\n",
    "        model = models[0]()\n",
    "        model.to(device)\n",
    "        losses[i,:] = torch.tensor(train(model, train_loader, models[3], 0, 25, verbose=False, siamese=models[1], aux=models[2], alpha = models[5]))\n",
    "        time2 = time.perf_counter()\n",
    "        times.append(time2 - time1)\n",
    "\n",
    "        tr_accuracy, te_accuracy = accu(model, train_loader, test_loader, siamese=models[1], aux=models[2])\n",
    "\n",
    "        accuracies.append(te_accuracy)\n",
    "    loss_total.append(losses)\n",
    "    index += 1\n",
    "    \n",
    "    print('For optimal model_%d, Mean accuracy: %.3f, Std: %.3f, Mean time: %.3f, Std: %.3f' %(index, torch.tensor(accuracies).mean(), torch.tensor(accuracies).std(), torch.tensor(times).mean(), torch.tensor(times).std()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
